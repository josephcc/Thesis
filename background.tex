\section{Evolving User Intention when Exploring Large Data}

Users often need to explore individual pieces of information in large and unfamiliar datasets. As they gradually examine more data, they build up a better mental landscape of the space of information, potentially adjusting their goals in the exploration process. One instance of this process are online exploratory search tasks where users start out with a high level, sometimes vague, idea about their goals and criteria. Consider a user starting out with a search query for finding “the best laptop for college.” Being unfamiliar with the topic, the user must first explore online reviews and articles in order to figure out what were the common options recommended in these sources, what were the important criteria these recommendations were based on, and which of these criteria fits the user’s personal preferences and context. This process is often exploratory, dynamic and opportunistic in nature, requiring users to learn from the individual webpages and reviews to iteratively refine their goals and preferences based on a better understanding of global context \cite{marchionini2006exploratory}. However, prior studies have shown that this process can incurring high mental and interaction efforts as new discoveries can potentially invalidate prior decisions, lead to better query terms \cite{belkin2003query,salton1990improving}, and open new research directions to pursuit \cite{pirolli1999information,pirolli2005sensemaking} requiring users to use a combination of external tools to keep track of all their decisions and progress made throughout these mental changes \cite{capra2010tools}.  

There have been several decades of research that have explored ways of getting users to more deeply externalize their intents and goals beyond short search queries in order to provide better support for this process \cite{jansen2000real}. For example, using prompt and text field designs that promote longer query terms \cite{franzen2000verbosity,belkin2003query}, asking for relevance feedback on the results provided \cite{salton1990improving,rui1998relevance,peltonen2017negative}, explicitly asking users to build up sets of query terms of different topics \cite{hearst1996visualizing,hoeber2006comparative}, or providing in-situ interfaces for note-taking \cite{notetoself}. However, research also found that it is very difficult to get users to put in the work to externalize and maintain their evolving interests tasks due to its volatile nature during exploratory search. In addition, interactions such as eliciting longer query terms or explicit relevance feedback, can have the perception that the work will not be sufficiently paid off in the future or not understanding how their work will affect their results. In this thesis, I introduced two mechanisms for providing immediate and sufficient benefits to exploratory searchers: 1) generating personalized and interactive visualizations for explaining items in a search results based on users’ current interest profile  (\Cref{chap:searchlens}); and 2) allowing users to keep track of their interpretation of online evidence about their different criteria and options to build a product comparison table (\Cref{chap:mesh}). I tested these mechanisms in two systems in controlled lab studies and field deployment studies, and found that users expressed significantly more to the system, and valued the benefits they provided.


\section{Structuring Information with Crowdsourcing}

Human computation approaches present new opportunities to harness deep semantic knowledge for exploring and organizing complex and unstructured data. For example, Cascade \cite{chilton2013cascade,bragg2013crowdsourcing} generated hierarchical categories from online forum discussions, but suffers from categories at the same level having varying specificity due to the limited context of each crowdworkers. Crowd Synthesis \cite{andre2014crowd} showed that simply showing more items to each crowdworker can lead to significant improvements, suggesting global context is a key element for crowd structuring. Fundamentally, most prior systems provide context by showing a small sample of items, hoping that they capture the distribution of information in the larger dataset. A complementary set of approaches has focused on the scaling through computation, applying approaches such as partial clustering \cite{yi2012crowdclustering}, learning similarity metrics \cite{tamuz2011adaptively}, or matrix completion \cite{yi2012semi}. While these have shown to be powerful on simple information such as visual patterns or colors using large numbers of split-second judgments, structuring complex exploratory search information can be difficult without providing novice crowdworkers with richer context or opportunities to learn from data. In \cref{chap:alloy}, I propose an alternative approach that builds up workers' mental models by allowing them to actively request for more context, identify discriminative keywords, and search the dataset for similar items, taking advantage of people's capacity of information foraging \cite{pirolli1999information}. The resulting structures were found to be more coherent than a state-of-the-art crowd and machine learning-based systems and at a lowered monetary cost compared to other crowd-based approaches. 


\section{Exploratory Search Interfaces}

Due to the ubiquity and high costs of exploratory search tasks to the users \cite{marchionini2006exploratory}, a major thread of work includes novel personalized search interfaces such as semantic web interfaces \cite{wilson2006mspace}, or computational approaches such as automatic or interactive result clustering \cite{cutting2017scatter}. Several exploratory search interfaces have been developed in order to help searchers orient themselves in the information space, review and explore the different subtopics, and keep track of their overall progress \cite{hearst2009search,marchionini2000agileviews,patterson2001predicting,tretter2013searchpanel,morris2008searchbar}. Two closely related studies include Topic-Relevance Map and Exploration Wall, which explored ways to provide overviews of search results of academic papers using document keywords and entities and easily choose keywords to build up subsequent queries \cite{peltonen2017topic,klouche2015designing}. 

Past studies have shown users rely on aggregating from multiple sources in order to verify online information as credible and make decisions \cite{fox2000online,cotten2004characteristics,racherla2012perceived}, but the process can be ``tedious and cumbersome'' leading to ``opening several tabs ... and then manually switch[ing] between them while trying to remember information on different pages'' \cite{greis2017increasing,bhavnani2005difficult}. Another domain of research focused on aggregation of information scattered across sources. For example, summarizing search results for complex exploratory search tasks has been an area of high research interests. Early threads of research include search results clustering \cite{zamir1999grouper,zeng2004learning}, review summarization \cite{manek2017aspect,yu2011aspect}, and identifying criteria about products from reviews \cite{hu2004mining,li2010structure}. While these top-down approaches have shown great benefits in helping people get an initial overview of the space of information with many making their way into commercial ecommerce websites, prior studies on consumer behavior have also shown that consumers often also rely on bottom-up approaches of deeply examining each pieces of information to gain insights and gradually build up a personal understanding of the information space \cite{gan2012helpfulness,mudambi2010research}. In the second half of this dissertation, I presented three systems for supporting global context by allowing users to express personal interests and use them to interpret multiple options  (\Cref{chap:searchlens}), cross-reference information about entity options scattered across webpages (\Cref{chap:weaver}), and keeping track of how users interpret individual pieces of evidence to gradually build up a global understanding of their options and criteria during online shopping research (\Cref{chap:mesh}). Through controlled lab studies and field deployment studies, I examine the costs and benefits of dynamically providing global context based on users’ current interests.
